{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## _Sprint - 4: Train the model on IBM_", "id": "1c2ca349"}, {"metadata": {}, "cell_type": "markdown", "source": "### _Team-ID: PNT2022TMID21613_", "id": "e7e30ece"}, {"metadata": {}, "cell_type": "markdown", "source": "#### Current Directory", "id": "bb3cc268"}, {"metadata": {}, "id": "b2f34ebe", "cell_type": "code", "source": "pwd", "execution_count": 1, "outputs": [{"output_type": "execute_result", "execution_count": 1, "data": {"text/plain": "'/home/wsuser/work'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "#### Installing keras and tensorflow", "id": "56a4c806"}, {"metadata": {"scrolled": true}, "id": "39e59100", "cell_type": "code", "source": "!pip install keras==2.2.4\n!pip install tensorflow", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Collecting keras==2.2.4\n  Using cached Keras-2.2.4-py2.py3-none-any.whl (312 kB)\nRequirement already satisfied: pyyaml in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (5.4.1)\nRequirement already satisfied: keras-applications>=1.0.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.0.8)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.20.3)\nRequirement already satisfied: h5py in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (3.2.1)\nRequirement already satisfied: keras-preprocessing>=1.0.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.1.2)\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.7.3)\nRequirement already satisfied: six>=1.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from keras==2.2.4) (1.15.0)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: keras 2.7.0\n    Uninstalling keras-2.7.0:\n      Successfully uninstalled keras-2.7.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.7.2 requires keras<2.8,>=2.7.0, but you have keras 2.2.4 which is incompatible.\u001b[0m\nSuccessfully installed keras-2.2.4\nRequirement already satisfied: tensorflow in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (2.7.2)\nRequirement already satisfied: tensorflow-estimator<2.8,~=2.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: tensorboard~=2.7 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.7.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.23.1)\nRequirement already satisfied: absl-py>=0.4.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.12.0)\nRequirement already satisfied: gast<0.5.0,>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.4.0)\nCollecting keras<2.8,>=2.7.0\n  Using cached keras-2.7.0-py2.py3-none-any.whl (1.3 MB)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.1.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.15.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (3.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (4.1.1)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.1.2)\nRequirement already satisfied: protobuf>=3.9.2 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (3.19.1)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (3.2.1)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.12.1)\nRequirement already satisfied: flatbuffers<3.0,>=1.12 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (2.0)\nRequirement already satisfied: numpy>=1.14.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.20.3)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (1.42.0)\nRequirement already satisfied: wheel<1.0,>=0.32.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorflow) (0.37.0)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (0.4.4)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (3.3.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (2.26.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (1.23.0)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (58.0.4)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (1.6.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (0.6.1)\nRequirement already satisfied: werkzeug>=0.11.15 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from tensorboard~=2.7->tensorflow) (2.0.2)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (4.2.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (0.2.8)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (4.7.2)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.7->tensorflow) (1.3.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard~=2.7->tensorflow) (0.4.8)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (1.26.7)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.7->tensorflow) (2.0.4)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.7->tensorflow) (3.2.1)\nInstalling collected packages: keras\n  Attempting uninstall: keras\n    Found existing installation: Keras 2.2.4\n    Uninstalling Keras-2.2.4:\n      Successfully uninstalled Keras-2.2.4\nSuccessfully installed keras-2.7.0\n", "name": "stdout"}]}, {"metadata": {}, "id": "32cc58d1", "cell_type": "markdown", "source": "### Understading the Data"}, {"metadata": {}, "id": "a3153089", "cell_type": "markdown", "source": "#### Importing Libraries"}, {"metadata": {}, "id": "da535ef6", "cell_type": "code", "source": "import numpy as np\nimport tensorflow\nimport keras\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.utils import np_utils", "execution_count": 3, "outputs": []}, {"metadata": {}, "id": "40e00b02", "cell_type": "markdown", "source": "#### Load Data"}, {"metadata": {}, "id": "be88eaa0", "cell_type": "code", "source": "(x_train, y_train), (x_test, y_test) = mnist.load_data()", "execution_count": 4, "outputs": []}, {"metadata": {}, "id": "a2acf68a", "cell_type": "code", "source": "print(x_train.shape)\nprint(x_test.shape)", "execution_count": 5, "outputs": [{"output_type": "stream", "text": "(60000, 28, 28)\n(10000, 28, 28)\n", "name": "stdout"}]}, {"metadata": {}, "id": "466c0f46", "cell_type": "markdown", "source": "#### Analysing the Data"}, {"metadata": {}, "id": "7adb841a", "cell_type": "code", "source": "x_train[0]", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0],\n       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n          0,   0]], dtype=uint8)"}, "metadata": {}}]}, {"metadata": {}, "id": "34d7dc79", "cell_type": "code", "source": "y_train[0]", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "5"}, "metadata": {}}]}, {"metadata": {}, "id": "3772e9c9", "cell_type": "code", "source": "import matplotlib.pyplot as plt\nplt.imshow(x_train[0])", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "<matplotlib.image.AxesImage at 0x7f9a138d8160>"}, "metadata": {}}, {"output_type": "display_data", "data": {"text/plain": "<Figure size 432x288 with 1 Axes>", "image/png": "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\n"}, "metadata": {"needs_background": "light"}}]}, {"metadata": {}, "id": "ba4d4dc2", "cell_type": "markdown", "source": "#### Reshaping the data"}, {"metadata": {}, "id": "fd0e4b01", "cell_type": "code", "source": "x_train = x_train.reshape(60000, 28, 28, 1).astype('float32')\nx_test = x_test.reshape(10000, 28, 28, 1).astype('float32')\nx_train[0]", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "array([[[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  3.],\n        [ 18.],\n        [ 18.],\n        [ 18.],\n        [126.],\n        [136.],\n        [175.],\n        [ 26.],\n        [166.],\n        [255.],\n        [247.],\n        [127.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 30.],\n        [ 36.],\n        [ 94.],\n        [154.],\n        [170.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [225.],\n        [172.],\n        [253.],\n        [242.],\n        [195.],\n        [ 64.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 49.],\n        [238.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [251.],\n        [ 93.],\n        [ 82.],\n        [ 82.],\n        [ 56.],\n        [ 39.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 18.],\n        [219.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [198.],\n        [182.],\n        [247.],\n        [241.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 80.],\n        [156.],\n        [107.],\n        [253.],\n        [253.],\n        [205.],\n        [ 11.],\n        [  0.],\n        [ 43.],\n        [154.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 14.],\n        [  1.],\n        [154.],\n        [253.],\n        [ 90.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [139.],\n        [253.],\n        [190.],\n        [  2.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 11.],\n        [190.],\n        [253.],\n        [ 70.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 35.],\n        [241.],\n        [225.],\n        [160.],\n        [108.],\n        [  1.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 81.],\n        [240.],\n        [253.],\n        [253.],\n        [119.],\n        [ 25.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 45.],\n        [186.],\n        [253.],\n        [253.],\n        [150.],\n        [ 27.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 16.],\n        [ 93.],\n        [252.],\n        [253.],\n        [187.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [249.],\n        [253.],\n        [249.],\n        [ 64.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 46.],\n        [130.],\n        [183.],\n        [253.],\n        [253.],\n        [207.],\n        [  2.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 39.],\n        [148.],\n        [229.],\n        [253.],\n        [253.],\n        [253.],\n        [250.],\n        [182.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 24.],\n        [114.],\n        [221.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [201.],\n        [ 78.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 23.],\n        [ 66.],\n        [213.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [198.],\n        [ 81.],\n        [  2.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 18.],\n        [171.],\n        [219.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [195.],\n        [ 80.],\n        [  9.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [ 55.],\n        [172.],\n        [226.],\n        [253.],\n        [253.],\n        [253.],\n        [253.],\n        [244.],\n        [133.],\n        [ 11.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [136.],\n        [253.],\n        [253.],\n        [253.],\n        [212.],\n        [135.],\n        [132.],\n        [ 16.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]],\n\n       [[  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.],\n        [  0.]]], dtype=float32)"}, "metadata": {}}]}, {"metadata": {}, "id": "49909952", "cell_type": "markdown", "source": "#### One Hot Encoding"}, {"metadata": {}, "id": "e8e0f267", "cell_type": "code", "source": "number_of_classes = 10\ny_train = np_utils.to_categorical(y_train, number_of_classes)\ny_test = np_utils.to_categorical(y_test, number_of_classes)", "execution_count": 10, "outputs": []}, {"metadata": {}, "id": "b64d8d9c", "cell_type": "code", "source": "y_train[0]", "execution_count": 11, "outputs": [{"output_type": "execute_result", "execution_count": 11, "data": {"text/plain": "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"}, "metadata": {}}]}, {"metadata": {}, "id": "aab36066", "cell_type": "markdown", "source": "### Model Building"}, {"metadata": {}, "id": "013a47a9", "cell_type": "markdown", "source": "#### Adding CNN "}, {"metadata": {}, "id": "53c3d04e", "cell_type": "code", "source": "model = Sequential()", "execution_count": 12, "outputs": []}, {"metadata": {}, "id": "ccdd2307", "cell_type": "code", "source": "model.add(Conv2D(32, (3,3),input_shape=(28, 28, 1), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))", "execution_count": 13, "outputs": []}, {"metadata": {}, "id": "0e7498e4", "cell_type": "code", "source": "model.add(Conv2D(64,(3,3), activation = 'relu'))\nmodel.add(Conv2D(64,(3,3), activation = 'relu'))", "execution_count": 14, "outputs": []}, {"metadata": {}, "id": "0aa7d8d0", "cell_type": "code", "source": "model.add(Conv2D(32,(3,3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))", "execution_count": 15, "outputs": []}, {"metadata": {}, "id": "aefa3bb7", "cell_type": "code", "source": "model.add(Flatten())\nmodel.add(Dense(10, activation = 'softmax'))", "execution_count": 16, "outputs": []}, {"metadata": {}, "id": "25638865", "cell_type": "code", "source": "model.summary()", "execution_count": 17, "outputs": [{"output_type": "stream", "text": "Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 26, 26, 32)        320       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 13, 13, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 11, 11, 64)        18496     \n                                                                 \n conv2d_2 (Conv2D)           (None, 9, 9, 64)          36928     \n                                                                 \n conv2d_3 (Conv2D)           (None, 7, 7, 32)          18464     \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 3, 3, 32)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 288)               0         \n                                                                 \n dense (Dense)               (None, 10)                2890      \n                                                                 \n=================================================================\nTotal params: 77,098\nTrainable params: 77,098\nNon-trainable params: 0\n_________________________________________________________________\n", "name": "stdout"}]}, {"metadata": {}, "id": "89c758f0", "cell_type": "markdown", "source": "#### Compiling the Model"}, {"metadata": {}, "id": "c7730126", "cell_type": "code", "source": "model.compile(loss=keras.losses.categorical_crossentropy, optimizer=tensorflow.keras.optimizers.Adam(), metrics=['accuracy'])", "execution_count": 18, "outputs": []}, {"metadata": {}, "id": "b1016563", "cell_type": "markdown", "source": "#### Train the model"}, {"metadata": {}, "id": "f57a0013", "cell_type": "code", "source": "model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 5, batch_size = 120)", "execution_count": 19, "outputs": [{"output_type": "stream", "text": "Epoch 1/5\n500/500 [==============================] - 49s 97ms/step - loss: 0.5320 - accuracy: 0.9008 - val_loss: 0.1009 - val_accuracy: 0.9680\nEpoch 2/5\n500/500 [==============================] - 49s 98ms/step - loss: 0.0788 - accuracy: 0.9760 - val_loss: 0.0662 - val_accuracy: 0.9799\nEpoch 3/5\n500/500 [==============================] - 47s 95ms/step - loss: 0.0534 - accuracy: 0.9829 - val_loss: 0.0586 - val_accuracy: 0.9810\nEpoch 4/5\n500/500 [==============================] - 47s 94ms/step - loss: 0.0410 - accuracy: 0.9876 - val_loss: 0.0498 - val_accuracy: 0.9855\nEpoch 5/5\n500/500 [==============================] - 47s 95ms/step - loss: 0.0330 - accuracy: 0.9895 - val_loss: 0.0421 - val_accuracy: 0.9870\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 19, "data": {"text/plain": "<keras.callbacks.History at 0x7f9a14bd59a0>"}, "metadata": {}}]}, {"metadata": {}, "id": "3d9e2cd6", "cell_type": "markdown", "source": "#### Testing the Model"}, {"metadata": {}, "id": "e582e9a0", "cell_type": "code", "source": "prediction = model.predict(x_test[:4])\nprediction", "execution_count": 20, "outputs": [{"output_type": "execute_result", "execution_count": 20, "data": {"text/plain": "array([[2.1654209e-08, 1.9998014e-08, 3.4166157e-04, 1.4985858e-07,\n        8.1087283e-11, 3.5488727e-11, 1.6825105e-17, 9.9965823e-01,\n        1.2591119e-09, 9.8944293e-09],\n       [6.4074619e-08, 1.0211050e-07, 9.9999964e-01, 5.8713021e-11,\n        9.6762834e-11, 7.9461287e-15, 6.7626480e-08, 7.2430562e-11,\n        1.9956554e-12, 9.3009897e-12],\n       [4.9178260e-07, 9.9996698e-01, 5.5315041e-08, 4.4848045e-09,\n        2.3077630e-05, 1.5436886e-08, 1.1440353e-06, 7.9526835e-06,\n        9.7287604e-08, 1.7961756e-07],\n       [9.9999058e-01, 6.4262032e-08, 4.6341288e-06, 1.8639275e-09,\n        1.5889897e-08, 2.3844827e-08, 2.8730060e-06, 4.2914405e-09,\n        1.8060895e-07, 1.5758064e-06]], dtype=float32)"}, "metadata": {}}]}, {"metadata": {}, "id": "afa8d556", "cell_type": "code", "source": "np.argmax(prediction, axis=1)", "execution_count": 21, "outputs": [{"output_type": "execute_result", "execution_count": 21, "data": {"text/plain": "array([7, 2, 1, 0])"}, "metadata": {}}]}, {"metadata": {}, "id": "86e0c1d9", "cell_type": "markdown", "source": "#### Observing the metrics"}, {"metadata": {}, "id": "9c8a236a", "cell_type": "code", "source": "metrics = model.evaluate(x_test, y_test, verbose=0)\nprint('METRICS\\n Loss: {:0.3f}\\n Accuracy: {:0.3f}'.format(metrics[0],metrics[1]))", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "METRICS\n Loss: 0.042\n Accuracy: 0.987\n", "name": "stdout"}]}, {"metadata": {}, "id": "ab3cac8c", "cell_type": "markdown", "source": "#### Saving the model"}, {"metadata": {}, "id": "5dff6936", "cell_type": "code", "source": "model.save('./models/IBM_mnistCNN.h5')", "execution_count": 23, "outputs": []}, {"metadata": {}, "id": "7ca9c54d", "cell_type": "markdown", "source": "<div class=\"alert alert-block alert-success\">\n<b>Contributed By: </b> Kavi Bharathi K (142219104056)\n</div>"}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 5}